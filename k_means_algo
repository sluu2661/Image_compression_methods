import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.image import imread

A = imread('C:\\Users\\Steven\\Desktop\\Stanford Machine Learning\\Lect 11-15\\ps3_data_files\\mandrill-large.tiff')

plt.imshow(A)
plt.show()

#large picture file is a 512 x 512 pixel image; each pixel is 3D encoding RGB values

A[:,:,0] #array containing the values for 'R'
A[:,:,1] #array containing the values for 'G'
A[:,:,2] #array containing the values for 'B'
#coding up a k-means algorithm to compress image files

#reshaping 3D array into a 2D array
large_raw = np.reshape(A,(A.shape[0]*A.shape[1],A.shape[2]))
#first, second, third column refer to R, G, B values

#number of unique RGB values of image
np.unique(large_raw,axis=0)

#we apply k-means to a smaller version of image A; 128 x 128 pixel image

small_A = imread('C:\\Users\\Steven\\Desktop\\Stanford Machine Learning\\Lect 11-15\\ps3_data_files\\mandrill-small.tiff')

#initial visualization
fig, axarr = plt.subplots(1,2, figsize=(8,8))

axarr[0].imshow(A)
axarr[0].set_title("Original large image")
axarr[1].imshow(small_A)
axarr[1].set_title("Original small image")

plt.show()


small_raw = np.reshape(small_A,(small_A.shape[0]*small_A.shape[1],small_A.shape[2]))

#number of clusters for modelling
clusters = 16

#let X be the input data; 2D array

def kmean(X, clusters = 16):
	#np.random.choice() takes inputs which are 1D arrays; 
	initial_clusters = X[np.random.choice(np.arange(X.shape[0]), size=clusters, replace=False)]
	k_means_clusters = initial_clusters
	tolerance = 1e6 #set initial arbitrary tolerance
	iterate_count = 1

	while tolerance > 1:
		labels = np.ones((X.shape[0],1))

		# determining closest cluster for each data query
		for i in range(X.shape[0]):
			dist = np.sqrt(np.sum((X[i] - k_means_clusters)**2, axis=1)) #calc dist between X[i] and each cluster
			labels[i] = dist.argmin(axis=0) #identifies which cluster is closest to X[i] (via index)

		# updating k_means_clusters
		new_clusters = np.zeros((clusters,X.shape[1]))
		for k in range(clusters):
			new_clusters[k] = np.sum((X * (labels == k)), axis=0) // np.sum(labels == k) # // for integer division!

		tolerance = np.sum(np.abs(new_clusters - k_means_clusters))
		k_means_clusters = new_clusters
		print("Interation {0}".format(iterate_count))
		iterate_count += 1
	print("kmeans algorithm has converged in {0} iterations".format(iterate_count-1))

	return k_means_clusters, labels

centroids, pixel_labels = kmean(small_raw, clusters) 

#need to reassign old pixels to new centroid values and convert back into 3D array

compressed_small = np.reshape(centroids[pixel_labels.astype(int)].astype(int),small_A.shape)

# final visualization for small
fig, axarr = plt.subplots(1,2, figsize=(8,8))

axarr[0].imshow(small_A)
axarr[0].set_title("Original small image")
axarr[1].imshow(compressed_small)
axarr[1].set_title("Compressed small image")
plt.show()

# applying kmeans algo to large image; this will most likely take a while to converge!
# rather than applying kmeans to large data set, we use the centroids found from the small one
# and assign to each pixel, its closest clustoid!

#finding the closest centroid of a given dataset 
def closestcentroids(X, C):
	labels = np.ones((X.shape[0],1))
	for i in range(X.shape[0]):
		dist = np.sqrt(np.sum((X[i] - C)**2, axis=1))
		labels[i] = dist.argmin(axis=0)
	return labels

pixel_labels_large = closestcentroids(large_raw, centroids)

compressed_large = np.reshape(centroids[pixel_labels_large.astype(int)].astype(int),A.shape)

# final visualization for large
fig, axarr = plt.subplots(1,2, figsize=(8,8))

axarr[0].imshow(A)
axarr[0].set_title("Original large image")
axarr[1].imshow(compressed_large)
axarr[1].set_title("Compressed large image")
plt.show()

n_colors_large = len(np.unique(large_raw,axis=0))
print("Image file has been compressed by a factor of {0}".format(n_colors_large / clusters))
